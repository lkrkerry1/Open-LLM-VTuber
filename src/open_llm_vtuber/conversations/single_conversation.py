from typing import Union, List, Dict, Any, Optional
import asyncio
import json
from loguru import logger
import numpy as np

from .conversation_utils import (
    create_batch_input,
    process_agent_output,
    send_conversation_start_signals,
    process_user_input,
    finalize_conversation_turn,
    cleanup_conversation,
    EMOJI_LIST,
)
from .types import WebSocketSend
from .tts_manager import TTSTaskManager
from ..chat_history_manager import store_message
from ..service_context import ServiceContext

# Import necessary types from agent outputs
from ..agent.output_types import SentenceOutput, AudioOutput


async def process_single_conversation(
    context: ServiceContext,
    websocket_send: WebSocketSend,
    client_uid: str,
    user_input: Union[str, np.ndarray],
    images: Optional[List[Dict[str, Any]]] = None,
    session_emoji: str = np.random.choice(EMOJI_LIST),
    metadata: Optional[Dict[str, Any]] = None,
) -> str:
    """Process a single-user conversation turn

    Args:
        context: Service context containing all configurations and engines
        websocket_send: WebSocket send function
        client_uid: Client unique identifier
        user_input: Text or audio input from user
        images: Optional list of image data
        session_emoji: Emoji identifier for the conversation
        metadata: Optional metadata for special processing flags

    Returns:
        str: Complete response text
    """
    # Create TTSTaskManager for this conversation
    tts_manager = TTSTaskManager()
    full_response = ""  # Initialize full_response here

    try:
        # Send initial signals
        await send_conversation_start_signals(
            websocket_send
        )
        logger.info(
            f"New Conversation Chain {session_emoji} started!"
        )

        # Process user input
        input_text = await process_user_input(
            user_input, context.asr_engine, websocket_send
        )

        # Create batch input
        batch_input = create_batch_input(
            input_text=input_text,
            images=images,
            from_name=context.character_config.human_name,
            metadata=metadata,
        )

        # Store user message (check if we should skip storing to history)
        skip_history = metadata and metadata.get(
            "skip_history", False
        )
        if context.history_uid and not skip_history:
            store_message(
                conf_uid=context.character_config.conf_uid,
                history_uid=context.history_uid,
                role="human",
                content=input_text,
                name=context.character_config.human_name,
            )

        if skip_history:
            logger.debug(
                "Skipping storing user input to history (proactive speak)"
            )

        logger.info(f"User input: {input_text}")
        if images:
            logger.info(f"With {len(images)} images")

        try:
            # agent.chat yields Union[SentenceOutput, Dict[str, Any]]
            agent_output_stream = context.agent_engine.chat(
                batch_input
            )

            async for output_item in agent_output_stream:
                if (
                    isinstance(output_item, dict)
                    and output_item.get("type")
                    == "tool_call_status"
                ):
                    # Handle tool status event: send WebSocket message
                    output_item["name"] = (
                        context.character_config.character_name
                    )
                    logger.debug(
                        f"Sending tool status update: {output_item}"
                    )

                    await websocket_send(
                        json.dumps(output_item)
                    )

                elif isinstance(
                    output_item,
                    (SentenceOutput, AudioOutput),
                ):
                    # Handle SentenceOutput or AudioOutput
                    response_part = await process_agent_output(
                        output=output_item,
                        character_config=context.character_config,
                        live2d_model=context.live2d_model,
                        tts_engine=context.tts_engine,
                        websocket_send=websocket_send,  # Pass websocket_send for audio/tts messages
                        tts_manager=tts_manager,
                        translate_engine=context.translate_engine,
                        default_avatar=context.character_config.avatar,
                    )
                    # Ensure response_part is treated as a string before concatenation
                    response_part_str = (
                        str(response_part)
                        if response_part is not None
                        else ""
                    )
                    full_response += response_part_str  # Accumulate text response
                else:
                    # å±æ€§æ£€æŸ¥ä½œä¸ºå›é€€ï¼ˆå…¼å®¹ç±»å‹ä¸ä¸€è‡´çš„æƒ…å†µï¼‰
                    if hasattr(
                        output_item, "display_text"
                    ) and hasattr(output_item, "tts_text"):
                        logger.debug(
                            f"Processing object as SentenceOutput via attribute fallback: {type(output_item)}"
                        )
                        response_part = await process_agent_output(
                            output=output_item,
                            character_config=context.character_config,
                            live2d_model=context.live2d_model,
                            tts_engine=context.tts_engine,
                            websocket_send=websocket_send,
                            tts_manager=tts_manager,
                            translate_engine=context.translate_engine,
                            default_avatar=context.character_config.avatar,
                        )
                        response_part_str = (
                            str(response_part)
                            if response_part is not None
                            else ""
                        )
                        full_response += response_part_str
                    elif hasattr(
                        output_item, "audio"
                    ) and hasattr(output_item, "text"):
                        # å¯é€‰çš„ AudioOutput å›é€€
                        logger.debug(
                            f"Processing object as AudioOutput via attribute fallback: {type(output_item)}"
                        )
                        response_part = await process_agent_output(
                            output=output_item,
                            character_config=context.character_config,
                            live2d_model=context.live2d_model,
                            tts_engine=context.tts_engine,
                            websocket_send=websocket_send,
                            tts_manager=tts_manager,
                            translate_engine=context.translate_engine,
                            default_avatar=context.character_config.avatar,
                        )
                        response_part_str = (
                            str(response_part)
                            if response_part is not None
                            else ""
                        )
                        full_response += response_part_str
                    else:
                        logger.warning(
                            f"Received unexpected item type from agent chat stream: {type(output_item)}"
                        )
                        logger.debug(
                            f"Unexpected item content: {output_item}"
                        )

        except Exception as e:
            logger.exception(
                f"Error processing agent response stream: {e}"
            )  # Log with stack trace
            await websocket_send(
                json.dumps(
                    {
                        "type": "error",
                        "message": f"Error processing agent response: {str(e)}",
                    }
                )
            )
            # full_response will contain partial response before error
        # --- End processing agent response ---

        # Wait for any pending TTS tasks
        if tts_manager.task_list:
            await asyncio.gather(*tts_manager.task_list)
            await websocket_send(
                json.dumps(
                    {"type": "backend-synth-complete"}
                )
            )

        await finalize_conversation_turn(
            tts_manager=tts_manager,
            websocket_send=websocket_send,
            client_uid=client_uid,
        )

        if context.history_uid and full_response:
            store_message(
                conf_uid=context.character_config.conf_uid,
                history_uid=context.history_uid,
                role="ai",
                content=full_response,
                name=context.character_config.character_name,
                avatar=context.character_config.avatar,
            )
            logger.info(f"AI response: {full_response}")

            # å‘é€ final full-text ç¡®ä¿æ°”æ³¡æ˜¾ç¤ºï¼ˆå·²æœ‰ï¼‰
            await websocket_send(
                json.dumps(
                    {
                        "type": "full-text",
                        "text": full_response,
                        "name": context.character_config.character_name,
                        "avatar": context.character_config.avatar,
                    }
                )
            )

            # æ³¨æ„ï¼šä¸å†å‘é€ user-input-transcription æ¥æ¨¡æ‹Ÿ AI å›å¤ï¼Œ
            # å› ä¸ºå‰ç«¯å·²ç»é€šè¿‡ audio æ¶ˆæ¯ä¸­çš„ display_text å°† AI å›å¤æ·»åŠ åˆ°å†å²è®°å½•ã€‚
            # å‘é€ user-input-transcription ä¼šå¯¼è‡´ AI å›å¤ä»¥ç”¨æˆ·æ ·å¼æ˜¾ç¤ºï¼ˆå¤´åƒåœ¨å³è¾¹ï¼‰ï¼Œ
            # å› æ­¤å·²åˆ é™¤ã€‚

        return full_response

    except asyncio.CancelledError:
        logger.info(
            f"ğŸ¤¡ğŸ‘ Conversation {session_emoji} cancelled because interrupted."
        )
        raise
    except Exception as e:
        logger.error(f"Error in conversation chain: {e}")
        await websocket_send(
            json.dumps(
                {
                    "type": "error",
                    "message": f"Conversation error: {str(e)}",
                }
            )
        )
        raise
    finally:
        cleanup_conversation(tts_manager, session_emoji)
